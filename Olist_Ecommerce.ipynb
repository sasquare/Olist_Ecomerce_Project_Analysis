{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1OooQjjnuquAedVoVg5aPICWZSHiJ5-Wu",
      "authorship_tag": "ABX9TyNKwnzM9rdM2ynNI4GRT3Vu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sasquare/Olist_Ecomerce_Project_Analysis/blob/main/Olist_Ecommerce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZpWVXcZzCWe"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M_B6gVtBzO_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opendatasets"
      ],
      "metadata": {
        "id": "n-s1tK_00ozK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "\n",
        "# Standard libs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from matplotlib.gridspec import GridSpec\n",
        "pd.set_option('display.max_columns', 100)\n",
        "import plotly.offline as py\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "import json\n",
        "import requests\n",
        "import folium\n",
        "import opendatasets as od\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "from pandas.api.types import CategoricalDtype\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "\n",
        "# Utilities\n",
        "#from viz_utils import *\n",
        "#from custom_transformers import *\n",
        "#from ml_utils import *\n",
        "\n",
        "# DataPrep\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "# Modeling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "rgNg1R9szkgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opendatasets --upgrade --quiet"
      ],
      "metadata": {
        "id": "0BW75cRA0xwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M8iDvWwa080b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = '/content/drive/MyDrive/olist/customers.csv'\n",
        "path2 ='/content/drive/MyDrive/olist/geolocation.csv'\n",
        "path3 ='/content/drive/MyDrive/olist/order_items.csv'\n",
        "path4 ='/content/drive/MyDrive/olist/order_payments.csv'\n",
        "path5 ='/content/drive/MyDrive/olist/order_reviews.csv'\n",
        "path6 ='/content/drive/MyDrive/olist/orders.csv'\n",
        "path7 ='/content/drive/MyDrive/olist/product_category.csv'\n",
        "path8 = '/content/drive/MyDrive/olist/products.csv'\n",
        "path9 = '/content/drive/MyDrive/olist/sellers.csv'\n"
      ],
      "metadata": {
        "id": "AD6oH78o3ziN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers=pd.read_csv(path1)\n",
        "geo_data=pd.read_csv(path2)\n",
        "order_item =pd.read_csv(path3)\n",
        "order_payment=pd.read_csv(path4)\n",
        "oder_review=pd.read_csv(path5)\n",
        "order=pd.read_csv(path6)\n",
        "category=pd.read_csv(path7)\n",
        "product=pd.read_csv(path8)\n",
        "seller=pd.read_csv(path9)"
      ],
      "metadata": {
        "id": "e3X-3fx24hhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking number of columns , column_names and no_of_rows\n",
        "\n",
        "datasets = [customers,geo_data,order_item, order_payment, oder_review, order,category,product, seller]\n",
        "titles = [\"customers\",\"geolocations\",\"items\", \"payments\", \"reviews\", \"orders\",\"category\",\"products\",\"sellers\"]\n",
        "\n",
        "\n",
        "\n",
        "info_df = pd.DataFrame({},)\n",
        "info_df['dataset']= titles\n",
        "\n",
        "info_df['no_of_columns']= [len(df.columns) for df in datasets ]\n",
        "info_df['columns_name']= [', '.join(list(df.columns)) for df in datasets]\n",
        "info_df['no_of_rows'] = [len(df) for df in datasets]\n",
        "\n",
        "info_df.style.background_gradient(cmap='Greys')"
      ],
      "metadata": {
        "id": "gLE5w0gf9rJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation(s):\n",
        "\n",
        "* Dataset with maximum number of columns is products.\n",
        "* Dataset with maximum number of rows is geolocations"
      ],
      "metadata": {
        "id": "-IK1BwOq_sZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking dtypes\n",
        "datasets = [customers,geo_data,order_item, order_payment, oder_review, order,category,product, seller]\n",
        "titles = [\"customers\",\"geolocations\",\"items\", \"payments\", \"reviews\", \"orders\",\"category\",\"products\",\"sellers\"]\n",
        "\n",
        "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "new_df = pd.DataFrame({},)\n",
        "new_df['dataset']= titles\n",
        "\n",
        "new_df['numeric_features'] = [len((df.select_dtypes(include=numerics)).columns) for df in datasets]\n",
        "new_df['num_features_name'] = [', '.join(list((df.select_dtypes(include=numerics)).columns)) for df in datasets]\n",
        "new_df['object_features'] = [len((df.select_dtypes(include='object')).columns) for df in datasets]\n",
        "new_df['objt_features_name'] = [', '.join(list((df.select_dtypes(include='object')).columns)) for df in datasets]\n",
        "new_df['bool_features'] = [len((df.select_dtypes(include='bool')).columns) for df in datasets]\n",
        "new_df.style.background_gradient(cmap='Greys')"
      ],
      "metadata": {
        "id": "V77C4pzP_urH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation(s):\n",
        "\n",
        "* products dataset has maximum number of numerical features(i.e dtype :'int16', 'int32', 'int64', 'float16', 'float32', 'float64').\n",
        "* orders dataset has maximum number of features of object dtype\n",
        "* We can also observe that all the timestamps are in object datatypes.So, we have to convert it into datetime type to do  analysis on these features."
      ],
      "metadata": {
        "id": "2QH09_cfAsHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking no of null values\n",
        "#code source-https://www.kaggle.com/fayhosseini/brazilian-e-commerce-eda-for-beginners\n",
        "\n",
        "datasets = [customers,geo_data,order_item, order_payment, oder_review, order,category,product, seller]\n",
        "titles = [\"customers\",\"geolocations\",\"items\", \"payments\", \"reviews\", \"orders\",\"category\",\"products\",\"sellers\"]\n",
        "\n",
        "info_df_n = pd.DataFrame({},)\n",
        "\n",
        "info_df_n['dataset']= titles\n",
        "\n",
        "#creating column of name of columns in the dataset\n",
        "info_df_n['cols'] = [', '.join([col for col, null in df.isnull().sum().items() ]) for df in datasets]\n",
        "\n",
        "#creating total number of columns in the dataset\n",
        "info_df_n['cols_no']= [df.shape[1] for df in datasets]\n",
        "\n",
        "#counting total null values\n",
        "info_df_n['null_no']= [df.isnull().sum().sum() for df in datasets]\n",
        "\n",
        "#creating total number of columns in the dataset with null-values\n",
        "info_df_n['null_cols_no']= [len([col for col, null in df.isnull().sum().items() if null > 0]) for df in datasets]\n",
        "\n",
        "#creating column of name of columns in the dataset with null-values\n",
        "info_df_n['null_cols'] = [', '.join([col for col, null in df.isnull().sum().items() if null > 0]) for df in datasets]\n",
        "\n",
        "\n",
        "info_df_n.style.background_gradient(cmap='Greys')"
      ],
      "metadata": {
        "id": "yMKLek-pAuqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation(s):\n",
        "\n",
        "* The maximum number of null-values are present in reviews dataset and the name of the columns with the null-values are review_comment_title and review_comment_message.\n",
        "* products dataset contains least number of null- values but most of its columns has null-values.\n",
        "* we have to deal with these null-values in future."
      ],
      "metadata": {
        "id": "f6X4W7DxErra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1.3. Merging all *datasets*"
      ],
      "metadata": {
        "id": "-WoRam9oE8Xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rev_new = oder_review.drop(['review_comment_title','review_creation_date','review_id','review_answer_timestamp'],axis=1)"
      ],
      "metadata": {
        "id": "j_fyURj1E__7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(order,order_payment, on=\"order_id\")\n",
        "df = df.merge(customers, on=\"customer_id\")\n",
        "df = df.merge(order_item, on=\"order_id\")\n",
        "df = df.merge(product, on=\"product_id\")\n",
        "df = df.merge(category, on=\"product_category_name\")\n",
        "df = df.merge(rev_new, on=\"order_id\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "tq1iW5RFFvH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of rows after merging:\",len(df))\n",
        "print(\"Number of columns after merging:\",len(df.columns))"
      ],
      "metadata": {
        "id": "WcDc-7CIHKQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1.3. Handling missing values"
      ],
      "metadata": {
        "id": "IqBT80hOHQAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "eZ17xWV1HRAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Missing values in Timestamps\n",
        "\n",
        "* The order of different types of timestamps are shown below:\n",
        "\n",
        "\n",
        "    order_purchase_timestamp-->order_approved_at--> order_delivered_carrier_date-->order_delivered_customer_date-->order_estimated_delivery_dat\n",
        "    e     \n",
        "\n",
        "* Timestamps containg missing values are order_approved_at, order_delivered_carrier_date, order_delivered_customer_date.\n",
        "\n",
        "* null-values in order_approved_at can be replaced by order_purchase_timestamp and null-values in order_delivered_customer_date can be replaced by order_estimated_delivery_date\n",
        "* we can drop the column order_delivered_carrier_date."
      ],
      "metadata": {
        "id": "yv37kIG6HZ6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling missing values\n",
        "index = (df[df['order_delivered_customer_date'].isnull() == True].index.values)\n",
        "\n",
        "df[\"order_approved_at\"].fillna(df[\"order_purchase_timestamp\"], inplace=True)\n",
        "df[\"order_delivered_customer_date\"].fillna(df[\"order_estimated_delivery_date\"], inplace=True)\n",
        "\n",
        "#dropping order delivery carrier date\n",
        "df.drop(labels='order_delivered_carrier_date',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "zynTZYwqHWKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the replaced values\n",
        "df.order_estimated_delivery_date[index[0]]"
      ],
      "metadata": {
        "id": "_6WllxTCI9Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.order_delivered_customer_date[index[0]]"
      ],
      "metadata": {
        "id": "J0CxGR3PJMDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing values of numerical features\n",
        "df['product_weight_g'].fillna(df['product_weight_g'].median(),inplace=True)\n",
        "df['product_length_cm'].fillna(df['product_length_cm'].median(),inplace=True)\n",
        "df['product_height_cm'].fillna(df['product_height_cm'].median(),inplace=True)\n",
        "df['product_width_cm'].fillna(df['product_width_cm'].median(),inplace=True)"
      ],
      "metadata": {
        "id": "-EHU24JqJkUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling missing values of text column\n",
        "print(\"Percentage of null reviews :\",(df.review_comment_message.isnull().sum()/len(df))*100 ,\"%\")\n",
        "# filling null value of review comments with no_review\n",
        "df['review_comment_message'].fillna('no_review',inplace=True)"
      ],
      "metadata": {
        "id": "Pk-n7gejJq3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1.4 Data Dedublicate"
      ],
      "metadata": {
        "id": "iIPLi67VKalj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dup_rows = df[df.duplicated(['order_id','customer_id','order_purchase_timestamp','order_delivered_customer_date','customer_unique_id','review_comment_message'])]\n",
        "dup_rows.head()"
      ],
      "metadata": {
        "id": "cjGhx42mKcuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deduplication of entries\n",
        "df= df.drop_duplicates(subset={'order_id','customer_id','order_purchase_timestamp','order_delivered_customer_date'}, keep='first', inplace=False)\n",
        "df=df.reindex()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "h2eiwCB6LFDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of rows after dedublication:\",len(df))\n",
        "print(\"Number of columns after deduplication:\",len(df.columns))"
      ],
      "metadata": {
        "id": "gTcxqq6zLpc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Data Analysis\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lSDjNwXYL5mB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2.1. High level Statistics"
      ],
      "metadata": {
        "id": "J67ZA7c4MBnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all time stamps are in object dtype as observed above converting it into dataetime\n",
        "df[['order_purchase_timestamp','order_approved_at','order_delivered_customer_date','order_estimated_delivery_date',]]=df[['order_purchase_timestamp',\n",
        "       'order_approved_at','order_delivered_customer_date','order_estimated_delivery_date']].apply(pd.to_datetime)\n"
      ],
      "metadata": {
        "id": "3AVj0Ab5L8hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Y2UGNV1BMXWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "* the final merged dataset has no null values.\n",
        "* total number of columns is 32.\n",
        "        dtype           |   number of columns\n",
        "        ----------------|-------------------\n",
        "        datetime64[ns]  |      4\n",
        "                        |\n",
        "        float64(10)     |      10\n",
        "                        |\n",
        "        int64           |      5\n",
        "                        |\n",
        "        object          |      13   "
      ],
      "metadata": {
        "id": "aRh3imQyMqpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "xBUVpQOeMr8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "\n",
        "* We can observe from the above table except customer_zip_code_prefix, order_item_id and review_score features we have 12 numerical features in our final dataset.\n",
        "\n",
        "* Also,We can observe the statistics like percentile values , mean and standard deviation values, count , min and max of the numerical featues.For payment_value, the maximum payment value of an order is 13664 Brazilian real.\n",
        "\n",
        "* For the price and freight value of an order. The maximum price of an order is 6735 while max freight is  around 410 Brazilian real. The average price of an order is around 125 Brazilian real and frieght value is around 20 Brazilian real. The order with minimum price of 0.85 Brazilian real have been made.\n",
        "\n",
        "* Similarly, we can observe the other features further we will see the  distribution of these features and see how they are  helping  in classifying the class labels and find other insights."
      ],
      "metadata": {
        "id": "GxE79_oTM_tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the target variables i.e review score\n",
        "df.review_score.value_counts()"
      ],
      "metadata": {
        "id": "PQX5hiJPNA_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def partition(x):\n",
        "    if x < 3:\n",
        "        return 0\n",
        "    return 1\n",
        "df['review_score']=df['review_score'].map(lambda cw : partition(cw) )\n",
        "\n",
        "# checking the review score now\n",
        "df.review_score.value_counts()"
      ],
      "metadata": {
        "id": "spXaBTobNv9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#counting the review score with 1 and 0\n",
        "y_value_counts = df.review_score.value_counts()\n",
        "\n",
        "#calculating the percentage of each review type\n",
        "print(\"Total Positive Reviews :\", y_value_counts[1], \", (\", (y_value_counts[1]/(y_value_counts[1]+y_value_counts[0]))*100,\"%)\")\n",
        "print(\"Total Negative Reviews :\", y_value_counts[0], \", (\", (y_value_counts[0]/(y_value_counts[1]+y_value_counts[0]))*100,\"%)\")\n",
        "print('\\n')\n",
        "\n",
        "#plotting bar-plot and pie chart\n",
        "%matplotlib inline\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.ylabel('Total Reviews')\n",
        "plt.xlabel('Label')\n",
        "plt.title('Negative Vs Positive Reviews',color='dimgrey')\n",
        "plt.xticks([10,10.20],['0','1'])\n",
        "#creating bar plots\n",
        "plt.bar(10,14112, color = 'grey', width = 0.15,alpha=0.7,label='negative',edgecolor='black')\n",
        "plt.bar(10.20,83143,color = '#2e4884', width = 0.15,alpha=0.9,label='positive',edgecolor='black')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "labels = ['Positive','Negative']\n",
        "sizes = [83143,14112]\n",
        "explode = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
        "color={'#2e4884','grey'}\n",
        "plt.pie(sizes,explode=explode ,colors=color,labels=labels, autopct='%1.1f%%',shadow=False, startangle=0,radius=1.5,labeldistance=1.1,textprops={'fontsize': 14},frame=True, )\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.title('Pie Chart for review score',color='dimgrey')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GVd37blFOqI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Observation(s):\n",
        "\n",
        "* We can observe from the above plots 85.5% of the total reviews are positive i.e. 1 and only 14.5% reviews are negative i.e. which means that the given data set is imbalanced dataset."
      ],
      "metadata": {
        "id": "9PjbTHlVTNOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation matrix\n",
        "corr_matrix = df.corr()"
      ],
      "metadata": {
        "id": "Q9I2JfRWTOTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,8))\n",
        "sns.set(font_scale=1.3)\n",
        "cmap = sns.light_palette(\"#2f3b39\",as_cmap=True)\n",
        "sns.heatmap(corr_matrix, cmap=cmap,annot=True)\n",
        "plt.title(\"  Correlation Matrix of the features\",fontsize=19)\n",
        "plt.savefig('plot16.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L3EfWljpTaE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "\n",
        "* There is a strong positive correlation between: (payment_value and price), (product_weight_g and freight_value also with product_width_cm), (product_length_cm and product_width_cm), (product_height_cm and product_weight_g)."
      ],
      "metadata": {
        "id": "qcjlLNJ6UscK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#finding corr- values of the features with review_score\n",
        "corr_matrix[\"review_score\"].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "8yFwA4JQUt4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking unique ids\n",
        "print(\"Total number of unique seller_id:\",len((df.seller_id).unique()))\n",
        "print(\"Total number of unique product_id:\",len((df.product_id).unique()))\n",
        "print(\"Total number of unique customer_id:\",len((df.customer_unique_id).unique()))"
      ],
      "metadata": {
        "id": "zEbOko38VGy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.ylabel('No of Unique_Ids')\n",
        "plt.xlabel('Different Unique_Ids')\n",
        "plt.title('Total Unique Ids',color='dimgrey')\n",
        "plt.xticks([10,10.25,10.50],['seller_id','product_id','customer_id'])\n",
        "#creating bar plots\n",
        "plt.bar(10,3022, color = 'grey', width = 0.25,alpha=0.7,label='seller_id',edgecolor='black')\n",
        "plt.bar(10.25,31053, color = 'white', width = 0.25,alpha=0.8,label='product_id',edgecolor='black')\n",
        "plt.bar(10.50,94087, color = '#2e4884', width = 0.25,alpha=0.9,label='customer_id',edgecolor='black')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zEs_umIEVSmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "* After comparing different ids it can be observed that the highest number of unique id is of customers and least is from sellers"
      ],
      "metadata": {
        "id": "b8yaJ2gNVpuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2.2. Uivariate Analysis: payment_type"
      ],
      "metadata": {
        "id": "oZr-aldkWy-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('payment_type').size()"
      ],
      "metadata": {
        "id": "Kio5Rtd0VsRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.ylabel('Total')\n",
        "plt.xlabel('payment_type')\n",
        "plt.title('Total payment_type',color='dimgrey')\n",
        "plt.xticks([10,10.25,10.50,10.75],['debit_card','voucher','boleto','credit_card'])\n",
        "#creating bar plots\n",
        "plt.bar(10.75,73816, color = '#2e4884', width = 0.25,alpha=0.8,label='credit_card',edgecolor='black')\n",
        "plt.bar(10.50,19345, color = '#d8d8d8', width = 0.25,label='boleto',edgecolor='black')\n",
        "plt.bar(10.25,2604, color = 'white', width = 0.25,alpha=0.5,label='voucher',edgecolor='black')\n",
        "plt.bar(10,1490, color = 'grey', width = 0.25,alpha=0.8,label='debit_card',edgecolor='black')\n",
        "\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "s= [ 73816,19345, 2604,1490]\n",
        "new = ['credit_card','boleto','voucher','debit_card']\n",
        "\n",
        "explode = (0, 0, 0,0)\n",
        "colours = {'credit_card': '#2e4884',\n",
        "           'boleto': '#d8d8d8',\n",
        "           'voucher': 'w',\n",
        "           'debit_card': 'grey'}\n",
        "\n",
        "color ={'#2e4884','grey','#d8d8d8','w'}\n",
        "\n",
        "\n",
        "\n",
        "plt.pie(s, explode=explode, labels=new,colors=[colours[key] for key in new] , autopct='%1.1f%%',shadow=False, startangle=70,radius=1.5,frame=True,textprops={'fontsize': 8})\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yzk4YDqrW9PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obsrervation(s):\n",
        "\n",
        "Note: **Baleto** ==> Boleto Bancário, simply referred to as Boleto (English: Ticket) is a payment method in Brazil regulated by FEBRABAN, short for Brazilian Federation of Banks.It can be paid at ATMs, branch facilities and internet banking of any Bank, Post Office, Lottery Agent and some supermarkets until its due date.\n",
        "* from the above plots we can observe that most of the orders are paid using credit card and the second most used payment method is boleto.\n",
        "\n",
        "* The percentage of each mode of payment is shown in pie chart which shows amonst the all payments made by the user the credit card is used by 75.9% of the users, baleto is used by 19.9% of the user and 3.2% of the user used voucher and debit card.\n"
      ],
      "metadata": {
        "id": "VInrOuWyXP2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = pd.DataFrame(df.groupby('payment_type')['review_score'].agg(lambda x: x.eq(1).sum())).reset_index()\n",
        "\n",
        "# Pandas dataframe grouby count: https://stackoverflow.com/a/19385591/4084039\n",
        "temp['total'] = list(pd.DataFrame(df.groupby('payment_type')['review_score'].agg([('total','count'),('Avg','mean')]))['total'])\n",
        "temp['Avg']   = list(pd.DataFrame(df.groupby('payment_type')['review_score'].agg([('total','count'),('Avg','mean')]))['Avg'])\n",
        "#sorting dataframe\n",
        "temp = temp.sort_values(by=['total'], ascending=True)"
      ],
      "metadata": {
        "id": "RdR4rie0XRTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Simplifing the plots using pareto plots\n",
        "def pareto_plot(df, x=None, y=None, title=None, show_pct_y=False, pct_format='{0:.0%}'):\n",
        "    xlabel = x\n",
        "    ylabel = y\n",
        "    tmp = df.sort_values(y, ascending=False)\n",
        "    x = tmp[x].values\n",
        "    y = tmp[y].values\n",
        "    weights = y / y.sum()\n",
        "    cumsum = weights.cumsum()\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(10,6))\n",
        "    ax1.bar(x, y,color='#2e4884',edgecolor='black',alpha=0.9)\n",
        "    ax1.set_xlabel(xlabel)\n",
        "    ax1.set_ylabel(ylabel)\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(x, cumsum, '-ro', alpha=0.5,color='black')\n",
        "    ax2.set_ylabel('', color='r')\n",
        "    ax2.tick_params('y', colors='r')\n",
        "\n",
        "    vals = ax2.get_yticks()\n",
        "    ax2.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
        "\n",
        "    # hide y-labels on right side\n",
        "    if not show_pct_y:\n",
        "        ax2.set_yticks([])\n",
        "\n",
        "    formatted_weights = [pct_format.format(x) for x in cumsum]\n",
        "    for i, txt in enumerate(formatted_weights):\n",
        "        ax2.annotate(txt, (x[i], cumsum[i]),fontsize=15)\n",
        "\n",
        "    if title:\n",
        "        plt.title(title,color='dimgrey',fontsize=15)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OzaT0dOPXrbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pareto_plot(temp,x='payment_type',y='total',title=\"Pareto Plot of counts of each payment type\")"
      ],
      "metadata": {
        "id": "h6bXIO37X0WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* we can observe from the above plots that 96 % of the user used credit card and boleto.With credit card , boleto and voucher it covers 98% of users. Now let us see,how it is related with the target variable i.e review score.Or we can say 98% chance that the customer will use credit_card or boleto or voucher."
      ],
      "metadata": {
        "id": "2_Gd4DbuYMHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us see how this categorical feature related with our target variable\n",
        "#code source-https://matplotlib.org/stable/gallery/lines_bars_and_markers/barh.html\n",
        "plt.figure(figsize=(12,8))\n",
        "p1=plt.barh(temp.payment_type,temp.total,color='grey',alpha=0.5)\n",
        "p2=plt.barh(temp.payment_type,temp.review_score,color='#2e4884',alpha=0.9)\n",
        "plt.title('Payment Types and user_counts',fontsize=15,color='dimgrey')\n",
        "plt.ylabel('payment_types',fontsize=14)\n",
        "plt.xlabel('Total',fontsize=14)\n",
        "plt.legend((p1[0], p2[0]), ('total_reviews', 'positive_review by users'))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uLZFnnctYNNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Observation(s):\n",
        "\n",
        "* We can observe from the above stacked plot that most of the customer who used credit card have given positive reviews.Also, for the boleto, voucher and the debit card user it is same.From this we can conclude that this can be our important categorical feature for the problem.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fZrbucn3ZAOO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.2.2 Univariate Analysis: Customer count based on State wise\n",
        "\n",
        "![alt text](https://st4.depositphotos.com/1374738/23094/v/950/depositphotos_230940566-stock-illustration-map-brazil-divisions-states.jpg)\n",
        "\n",
        "[link text](https://)\n",
        "- Image Source : https://st4.depositphotos.com/1374738/23094/v/950/depositphotos_230940566-stock-illustration-map-brazil-divisions-states.jpg"
      ],
      "metadata": {
        "id": "Ga62QvlbZFtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# State with the consumers count\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.set_style(\"whitegrid\")\n",
        "ax = df.customer_state.value_counts().sort_values(ascending=False)[0:15].plot(kind='bar', color = 'grey', alpha=0.8)\n",
        "ax.set_title(\"Top 15 consumer states of Brazil\")\n",
        "ax.set_xlabel(\"States\")\n",
        "plt.xticks(rotation=35)\n",
        "ax.set_ylabel(\"No of consumers\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Os_MhEw3ZB-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "\n",
        "* 42% of total consumers are from the SP(São Paulo), 12.9 % are from RJ(Rio de Janeiro) and 11.7 % are from MG(Minas Gerais) which means most of consumers are from these states.Also from the above map we can observe these are neighbouring staes these staes are most active.Now, Let us see what type of reviews are given from the consumer of these states.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r_VGLleyZh1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#stacked bar plots matplotlib: https://matplotlib.org/gallery/lines_bars_and_markers/bar_stacked.html\n",
        "def stack_plot(data, xtick, col2, col3='total'):\n",
        "    ind = np.arange(data.shape[0])\n",
        "\n",
        "    plt.figure(figsize=(20,5))\n",
        "    p1 = plt.bar(ind, data[col3].values,color = 'grey',alpha=0.5)\n",
        "    p2 = plt.bar(ind, data[col2].values,color= '#2e4884',alpha=0.8)\n",
        "\n",
        "    plt.ylabel('Reviews')\n",
        "    plt.title('% of review_score  ')\n",
        "    plt.xticks(ind-0.1, list(data[xtick].values), rotation=0)\n",
        "    plt.legend((p1[0], p2[0]), ('total_reviews', 'positive_review'))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gfV3EC4CZcTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of zeros in dataframe python: https://stackoverflow.com/a/51540521/4084039\n",
        "temp_1 = pd.DataFrame(df.groupby('customer_state')['review_score'].agg(lambda x: x.eq(1).sum())).reset_index()\n",
        "\n",
        "# Pandas dataframe grouby count: https://stackoverflow.com/a/19385591/4084039\n",
        "\n",
        "\n",
        "temp_1['total'] = list(pd.DataFrame(df.groupby('customer_state')['review_score'].agg([('total','count'),('Avg','mean')]))['total'])\n",
        "temp_1['Avg']   = list(pd.DataFrame(df.groupby('customer_state')['review_score'].agg([('total','count'),('Avg','mean')]))['Avg'])\n",
        "temp_1= temp_1.rename(columns={'review_score':'positive_review'})\n",
        "temp_1= temp_1.sort_values(by=['total'], ascending=False)"
      ],
      "metadata": {
        "id": "o_tkMBxOZ-Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_1"
      ],
      "metadata": {
        "id": "qZn2TZTOaA4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stack_plot(temp_1,'customer_state',col2='positive_review', col3='total')"
      ],
      "metadata": {
        "id": "CdI8dcNkaRxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "\n",
        "* From the avove stack plot of reviews per state we can conclude that most of consumers from each state has given positive reviews.In **SP** state from the total reviews of 40800 , 35791 reviews are positive reviews and for **RJ** state 9968 reviews are positive from the total reviews 12569.The consumer_state can be our important feature for the problem.\n",
        "\n"
      ],
      "metadata": {
        "id": "E8mPLfyEabnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2.2 Univariate Analysis: product_category_name_english"
      ],
      "metadata": {
        "id": "P26Qzhp9ah8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# State with the consumers count\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.set_style(\"whitegrid\")\n",
        "ax = df.product_category_name_english.value_counts().sort_values(ascending=False)[0:15].plot(kind='bar', color = 'grey', alpha=0.8)\n",
        "ax.set_title(\"Top selling product categories\")\n",
        "ax.set_xlabel(\"States\")\n",
        "plt.xticks(rotation=90)\n",
        "ax.set_ylabel(\"No of Orders\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cOhBLD2YaeNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  temp_2 = pd.DataFrame(df.groupby('product_category_name_english')['review_score'].agg(lambda x: x.eq(1).sum())).reset_index()\n",
        "\n",
        "  # Pandas dataframe grouby count: https://stackoverflow.com/a/19385591/4084039\n",
        "\n",
        "\n",
        "  temp_2['total'] = list(pd.DataFrame(df.groupby('product_category_name_english')['review_score'].agg([('total','count'),('Avg','mean')]))['total'])\n",
        "  temp_2['Avg']   = list(pd.DataFrame(df.groupby('product_category_name_english')['review_score'].agg([('total','count'),('Avg','mean')]))['Avg'])\n",
        "  temp_2 = temp_2.sort_values(by=['total'], ascending=True)\n",
        "  temp_2"
      ],
      "metadata": {
        "id": "F-ttZYL4a2By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code source-https://matplotlib.org/stable/gallery/lines_bars_and_markers/barh.html\n",
        "plt.figure(figsize=(22,18))\n",
        "plt.barh(temp_2.product_category_name_english,temp_2.total,color='grey',alpha=0.4)\n",
        "plt.barh(temp_2.product_category_name_english,temp_2.review_score,color='#2e4884',alpha=0.7)\n",
        "plt.title('Top Selling Product Categories in Brazilian E-Commerce (2016-2018)',fontsize=22,color='dimgrey')\n",
        "plt.ylabel('product_category_name_english',fontsize=14)\n",
        "plt.xlabel('Total',fontsize=14)\n",
        "plt.savefig('plot14.png', dpi=480, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XQUFzziEbARh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "* From the first plot titled  Top selling product categories we can conclude that most ordered products is from bed_bath_table category ,health beauty and sports_leisure between 2016 and 2018.The least ordered products are from security_and_services.\n",
        "\n",
        "* The second plot is stack plot which shows the total reviews and the reviews with positive sense.from this plot we can conclude that most of the reviews for the product category bed_bath_table are positive and it is same for the other product categories.This can be our important categorical feature for the problem."
      ],
      "metadata": {
        "id": "Mk6iIt7obI0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.2. Uivarite Analysis:frequency of orders Vs Number of Consumers"
      ],
      "metadata": {
        "id": "1THI5xZvbYV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting frequency orders vs  the number of consumers\n",
        "plt.figure(figsize=(14,8))\n",
        "\n",
        "#counting the consumers and converting it into percentage to visualize the distribution properly\n",
        "num_orders=df['customer_unique_id'].value_counts().value_counts()/df.shape[0]*100\n",
        "num_orders=num_orders.reset_index()\n",
        "#renaming the columns\n",
        "num_orders.rename(columns={'index':'number of orders', 'customer_unique_id':'log percentage of customers'},inplace=True)\n",
        "\n",
        "#plotting bar plot\n",
        "sns.barplot(data=num_orders,x='number of orders',y='log percentage of customers',palette='gray')\n",
        "plt.yscale('log') #log scale\n",
        "plt.title('Number of orders per customer',color='dimgrey')"
      ],
      "metadata": {
        "id": "62q51eFlbLpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "* Most of the consumer given order of any  products only for  one times and few consumers are also present who oredred products more than 35 times. From this we can say order frequecy can be used as important feature for the problem."
      ],
      "metadata": {
        "id": "6S9DF4u4bvoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 Univariate Analysis: Order_status"
      ],
      "metadata": {
        "id": "lzs9L7M4b1iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_univariate_analysis(data, column):\n",
        "    # Perform univariate analysis on the specified column\n",
        "    column_counts = data[column].value_counts()\n",
        "    print(column_counts)\n",
        "\n",
        "    total_count = len(data[column])\n",
        "    fig, ax = plt.subplots(figsize=(14, 6))\n",
        "    sns.countplot(data=data, x=column, ax=ax, palette=['grey'])\n",
        "\n",
        "    for p in ax.patches:\n",
        "        height = p.get_height()\n",
        "        ax.text(p.get_x() + p.get_width() / 2., height, f'{height}\\n{height/total_count:.2%}', ha=\"center\", fontsize=12, color='black')\n",
        "\n",
        "    plt.title(f'{column} Analysis', color='dimgrey')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Y-20f84phiry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform univariate analysis on 'order_status'\n",
        "perform_univariate_analysis(df, column='order_status')"
      ],
      "metadata": {
        "id": "RFrAQG-bhk5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_univariate_analysis(data, column):\n",
        "    # Perform univariate analysis on the specified column\n",
        "    column_counts = data[column].value_counts()\n",
        "    print(column_counts)\n",
        "\n",
        "    total_count = len(data[column])\n",
        "    fig, ax = plt.subplots(figsize=(14, 6))\n",
        "    sns.countplot(data=data, x=column, ax=ax, palette=['grey', '#425a90'], hue='review_score')\n",
        "\n",
        "    for p in ax.patches:\n",
        "        height = p.get_height()\n",
        "        ax.text(p.get_x() + p.get_width() / 2., height, f'{height}\\n{height/total_count:.2%}', ha='center', fontsize=12, color='black')\n",
        "\n",
        "    plt.title(f'{column} with % of Reviews', color='dimgrey')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3Y3pKkPZij-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform univariate analysis on 'order_status'\n",
        "perform_univariate_analysis(df, column='order_status')"
      ],
      "metadata": {
        "id": "eLMVDjK8imQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "\n",
        "* The first plot shows that 97.8% of the orders of status delivered and remaining precentage are with status shipped,canceled,invoiced,processing,unavailable and approved.\n",
        "\n",
        "* The second plot shows that for the order_status delivered most of the order are with positive reviews i.e 85% and only 12.8% are negative reviews."
      ],
      "metadata": {
        "id": "zrWw5habi_xh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.2.2 Univariate Analysis on different Timestamps"
      ],
      "metadata": {
        "id": "ZfJIqWD-jaxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calulating number of days for the data is taken\n",
        "print(df.order_approved_at.max() - df.order_approved_at.min(), ' from ',\n",
        "      df.order_approved_at.min(), ' to ', df.order_approved_at.max())"
      ],
      "metadata": {
        "id": "XAZ9TcMBjBQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code source-https://stackoverflow.com/questions/25146121/extracting-just-month-and-year-separately-from-pandas-datetime-column\n",
        "\n",
        "# Extracting attributes for purchase date - Year and Month\n",
        "df['order_purchase_year'] = df['order_purchase_timestamp'].apply(lambda x: x.year) #gives year Example :2016-10-04 09:43:32 ---->2016\n",
        "df['order_purchase_month'] = df['order_purchase_timestamp'].apply(lambda x: x.month) #gives month Example :2016-10-04 09:43:32 ---->10\n",
        "df['order_purchase_month_name'] = df['order_purchase_timestamp'].apply(lambda x: x.strftime('%b'))#gives month in short form Example :2016-10-04 09:43:32 ---->10--> Oct\n",
        "df['order_purchase_year_month'] = df['order_purchase_timestamp'].apply(lambda x: x.strftime('%Y%m'))#gives month&year Example :2016-10-04 09:43:32 ---->201610\n",
        "df['order_purchase_date'] = df['order_purchase_timestamp'].apply(lambda x: x.strftime('%Y%m%d'))#gives month,yr and date  Example :2016-10-04 09:43:32 ---->20161004\n",
        "df['order_purchase_month_yr'] = df['order_purchase_timestamp'].apply(lambda x: x.strftime(\"%b-%y\"))\n",
        "\n",
        "# Extracting attributes for purchase date - Day and Day of Week\n",
        "df['order_purchase_day'] = df['order_purchase_timestamp'].apply(lambda x: x.day)\n",
        "df['order_purchase_dayofweek'] = df['order_purchase_timestamp'].apply(lambda x: x.dayofweek)\n",
        "df['order_purchase_dayofweek_name'] = df['order_purchase_timestamp'].apply(lambda x: x.strftime('%a'))\n",
        "\n",
        "# Extracting attributes for purchase date - Hour and Time of the Day\n",
        "df['order_purchase_hour'] = df['order_purchase_timestamp'].apply(lambda x: x.hour)\n",
        "hours_bins = [-0.1, 6, 12, 18, 23]\n",
        "hours_labels = ['Dawn', 'Morning', 'Afternoon', 'Night']\n",
        "df['order_purchase_time_day'] = pd.cut(df['order_purchase_hour'], hours_bins, labels=hours_labels)\n",
        "\n",
        "# New DataFrame after transformations\n",
        "df.head()"
      ],
      "metadata": {
        "id": "jinTwMJHjrWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.lineplot(data=df['order_purchase_year_month'].value_counts().sort_index(),\n",
        "             color='black', linewidth=2)\n",
        "plt.title('Evolution of Total Orders in Brazilian E-Commerce', size=14, color='dimgrey')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gEqdyhPGkF18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "* from the above plot we can observe that the number of purchase is increasing from 201609 to 201711(highest) and then decreases for a short sapn which means the either orders from the older customers are increasing or the number of consumers are increasing."
      ],
      "metadata": {
        "id": "EB4XKTn7kQdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_month = pd.DataFrame()\n",
        "df_month['date'],df_month['review_score']= list(df.order_approved_at),list(df.review_score)\n",
        "df_month=df_month.dropna()\n",
        "df_month = df_month.sort_values(by=['date'])"
      ],
      "metadata": {
        "id": "x0sfRIqnkSiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_month['monthcount'] = list(df_month.date.apply(lambda x: x.strftime(\"%b-%y\")))\n",
        "#plotting number of orders per month-year\n",
        "plt.figure(figsize=(18,6))\n",
        "g = sns.countplot(x=df_month.monthcount,data=df_month,color='grey',edgecolor='grey')\n",
        "g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
        "g.set_xlabel('Month-Year')\n",
        "g.set_ylabel('Orders Count')\n",
        "plt.title('Number of orders per month-year', size=14, color='dimgrey');"
      ],
      "metadata": {
        "id": "i7YaBmIhsgeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting number of positive and negative reviews per month-year\n",
        "plt.figure(figsize=(18,6))\n",
        "g = sns.countplot(x=df_month.monthcount,hue='review_score',data=df_month,palette=['grey','#425a90'],edgecolor='grey')\n",
        "g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
        "g.set_xlabel('Month-Year')\n",
        "g.set_ylabel('Orders Count')\n",
        "plt.title('Number of positive and negative reviews per month-year', size=14, color='dimgrey');"
      ],
      "metadata": {
        "id": "UwueEicZsmX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "* From the first plot titled Number of orders per month-year show the total number order received per month on each each between 2016 and 2018.It can be observeed that in the month of November in the year 2017 the highest number of orders are received which is more the 7000 approx. and the leat number of orders are received in the month of Dec in the year 2016.\n",
        "\n",
        "* The second plot shows the total number of positive and negative reviews given for each order  per month-year.It can observed that  most the orders have given positive reviews.From the above plot we observed that on NOV-17 the highest orders were received but from the second plot we can see the highest positive reviews were given on May-18"
      ],
      "metadata": {
        "id": "HAfiiIgfsvwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.gridspec import GridSpec"
      ],
      "metadata": {
        "id": "sgaMBaN3ttc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the figure and axes\n",
        "fig = plt.figure(constrained_layout=True, figsize=(13, 10))\n",
        "gs = GridSpec(2, 2, figure=fig)\n",
        "ax1 = fig.add_subplot(gs[1, 0])\n",
        "ax2 = fig.add_subplot(gs[0, :])\n",
        "ax3 = fig.add_subplot(gs[1, 1])\n",
        "\n",
        "# Barchart - Total Reviews by time of the day\n",
        "time_of_day_counts = df['order_purchase_time_day'].value_counts()\n",
        "sns.countplot(data=df, x='order_purchase_time_day', ax=ax1, order=time_of_day_counts.index, palette=['grey', '#2e4884'], hue='review_score')\n",
        "ax1.set_title('Total Reviews by Time of the Day', size=14, color='dimgrey', pad=20)\n",
        "\n",
        "# Barchart - Total Reviews by month\n",
        "month_counts = df['order_purchase_month_name'].value_counts()\n",
        "sns.countplot(data=df, x='order_purchase_month_name', ax=ax2, order=month_counts.index, palette=['grey', '#2e4884'], hue='review_score')\n",
        "ax2.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation=45, ha='right')\n",
        "ax2.set_title('Total Reviews by Month', size=14, color='dimgrey', pad=20)\n",
        "\n",
        "# Barchart - Total Reviews by day of the week\n",
        "day_of_week_counts = df['order_purchase_dayofweek'].value_counts()\n",
        "sns.countplot(data=df, x='order_purchase_dayofweek', ax=ax3, order=day_of_week_counts.index, palette=['grey', '#2e4884'], hue='review_score')\n",
        "weekday_label = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "ax3.set_xticklabels(weekday_label, rotation=0, ha='center')\n",
        "ax3.set_title('Total Reviews by Day of Week', size=14, color='dimgrey', pad=20)\n",
        "\n",
        "# Fine-tune the layout\n",
        "fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "\n",
        "# Save and display the figure\n",
        "plt.savefig('plot14.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KfAXJ_MiswtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "* From the subplot titled Total Reviews by Month we can observe that the highest % of positive reviews amongst the total reviews between 2016 to 2018 are given on the month of feb i.e 9.8%.In the month of May and July amongst the total reviews there are more than 9.0% reviews are positive.\n",
        "\n",
        "* From the second subplot titled Total Reviews by Time of the day ,we can conclude that maximum number of orders are received in afternoon and the highest % of positive reviews are given on that time i.e 32.8%.\n",
        "\n",
        "* From the third subplot titled Total Reviews by day of the week  ,we can conclude that maximum number of orders are received on Monday and the highest % of positive reviews are given on that day  and Tuesday i.e 13.9%.\n"
      ],
      "metadata": {
        "id": "R-9LLC41u__s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ploting plot for the Total Number orders based on the Total delivery Time(Days)\n",
        "#https://stackoverflow.com/questions/60229375/solution-for-specificationerror-nested-renamer-is-not-supported-while-agg-alo\n",
        "df['day_to_delivery']=((df['order_delivered_customer_date']-df['order_purchase_timestamp']).dt.days)"
      ],
      "metadata": {
        "id": "8bR7lrcru9WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev = pd.DataFrame()\n",
        "df_dev['day_to_delivery'],df_dev['review_score']= list(df.day_to_delivery),list(df.review_score)\n",
        "df_dev=df_dev.dropna()"
      ],
      "metadata": {
        "id": "tZuiNqepvI6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(22,6))\n",
        "plt.title('Order Counts Based on Total delivery Time(in Days)', color='dimgrey')\n",
        "g = sns.countplot(x=df_dev.day_to_delivery,data=df_dev,color='gray')\n",
        "g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
        "g.set_xlabel('Total Days')\n",
        "g.set_ylabel('Orders Count');"
      ],
      "metadata": {
        "id": "5U5_54v9vMEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "* It can be observed that the maximum number of orders are delivered in 7 days few orders are also delivered in more than 30 days.The total deliver time can be a new feature to solve this problem."
      ],
      "metadata": {
        "id": "JKhWaeSm1gvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2.2 Univariate Analysis on Numerical Features\n",
        "* Price"
      ],
      "metadata": {
        "id": "VgBQWZ-I1knl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure()\n",
        "sns.set_style(\"whitegrid\")\n",
        "ax = sns.FacetGrid(df, hue=\"review_score\", height=5,aspect=2.0,palette=['#2e4884','black'])\n",
        "ax = ax.map(sns.distplot, \"price\").add_legend();\n",
        "plt.title('Distribution of product price per class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kOPrsa4Q1f0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The above distribution plot shows the distribution of price for both the postive and negative classes. We can observe that there is almost completely overlap of both the distribution for positive and negative class which suggests that it is not possible to classify them based only on price feature."
      ],
      "metadata": {
        "id": "zJo04AKS1v8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* freight_value"
      ],
      "metadata": {
        "id": "TOPIwmGh1zWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting distributions of freight_value per class\n",
        "plt.figure()\n",
        "#sns.set_style(\"whitegrid\")\n",
        "ax = sns.FacetGrid(df, hue=\"review_score\", height=5,aspect=2.0,palette=['#000080','black'])\n",
        "ax = ax.map(sns.distplot, \"freight_value\").add_legend();\n",
        "plt.title('Distribution of freight_value per class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HS81Bg8p1s7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The above distribution plot shows the distribution of freight_value for both the postive and negative classes. We can observe that there is almost completely overlap of both the distribution for positive and negative class which suggests that it is not possible to classify them based only on freight_value feature."
      ],
      "metadata": {
        "id": "RoN9cIeb2Bnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* product_height_cm"
      ],
      "metadata": {
        "id": "8Z17zkED2Fhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting distributions of product_height_cm per class\n",
        "sns.set_style(\"whitegrid\")\n",
        "ax = sns.FacetGrid(df, hue=\"review_score\", height=5,aspect=2.0,palette=['#2e4884','black'])\n",
        "ax = ax.map(sns.distplot, \"product_height_cm\").add_legend();\n",
        "plt.title('Distribution of product_height_cm per class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wa3w0YxO2Ck_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The above distribution plot shows the distribution of product_height_cm for both the postive and negative classes. We can observe that most of the product has height less than 20 .Also, there is almost completely overlap of both the distribution for positive and negative class which suggests that it is not possible to classify them based only on product_height_cm feature."
      ],
      "metadata": {
        "id": "k7VLYjLo2LCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "product_weight_g"
      ],
      "metadata": {
        "id": "eDDnCLqK2Ngt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# distriution plot of product_weight_g\n",
        "plt.figure()\n",
        "sns.set_style(\"whitegrid\")\n",
        "ax = sns.FacetGrid(df, hue=\"review_score\", height=5,aspect=2.0,palette=['#2e4884','black'])\n",
        "ax = ax.map(sns.distplot, \"product_weight_g\").add_legend();\n",
        "plt.title('Distribution of product_weight_g per class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WvTr7leN2Q1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The above distribution plot shows the distribution of product_weight_g for both the postive and negative classes. We can observe that most of the product has weight less than 5000 gm .Also, there is almost completely overlap of both the distribution for positive and negative class which suggests that it is not possible to classify them based only on product_weight_g feature."
      ],
      "metadata": {
        "id": "FmRfJR8k2W52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* payment_value"
      ],
      "metadata": {
        "id": "wLULC8St2X0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# distriution plot of payment_value\n",
        "plt.figure()\n",
        "sns.set_style(\"whitegrid\")\n",
        "ax = sns.FacetGrid(df, hue=\"review_score\", height=5,aspect=2.0,palette=['#2e4884','black'])\n",
        "ax = ax.map(sns.distplot, \"payment_value\").add_legend();\n",
        "plt.title('Distribution of payment_value per class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lt2l9JEJ2anG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The above distribution plot shows the distribution of payment_value for both the postive and negative classes. We can observe that there is almost completely overlap of both the distribution for positive and negative class which suggests that it is not possible to classify them based only on payment_value feature."
      ],
      "metadata": {
        "id": "-tdktOpz2hXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Box Plot"
      ],
      "metadata": {
        "id": "X3EFV9Fm2iGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(14,6))\n",
        "\n",
        "box_plot_data=[df.product_length_cm,df.product_height_cm,df.product_width_cm]\n",
        "plt.boxplot(box_plot_data,labels=['product_length_cm','product_height_cm','product_width_cm'],vert=False)\n",
        "plt.title(\"Box Plots of Product Dimensions\")\n",
        "plt.savefig('plot24.png', dpi=400, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WCDTTcem2kPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,6))\n",
        "\n",
        "box_plot_data=[df.payment_value,df.price]\n",
        "plt.boxplot(box_plot_data,labels=['payment_value','price'],vert=False)\n",
        "plt.title(\"Box Plots of Different Prices\")\n",
        "plt.savefig('plot25.png', dpi=400, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xFlt5D682syZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The  above box plots are showing the distribution of  the numerical features product_width_cm, product_height_cm and product_width_cm. These features are overlapping each other.\n",
        "\n",
        "* Now, let us go and do some bivariate analysis and see if we use more than one feature at time, can we come with something to classify these features."
      ],
      "metadata": {
        "id": "CKpm7pJA2xYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2.3.Bivariate Analysis"
      ],
      "metadata": {
        "id": "U9BjwP8121Rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Distribution of price vs freight_value per class\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.set_style(\"whitegrid\")\n",
        "ax = sns.scatterplot(x='price',y='freight_value', data = df, hue=\"review_score\",palette=['#2e4884','grey'])\n",
        "plt.title('Distribution of price vs freight_value per class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SBsQ0gbA2yOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Distribution of price vs product_weight_g per class\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.set_style(\"whitegrid\")\n",
        "ax = sns.scatterplot(x='price',y='product_weight_g', data = df, hue=\"review_score\",palette=['#2e4884','grey'])\n",
        "plt.title('Distribution of price vs product_weight_g per class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uY__Z1Kw2vVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obervation(s):\n",
        "\n",
        "* From the above two scatter plots titled `Distribution of price vs freight_value per class` and `Distribution of price vs product_weight_g per class` respectively, It is very hard to say anything about the reviews on the basis of these plot as data-points are not seperable based on reviews these are completely mixed data."
      ],
      "metadata": {
        "id": "u8OVu2aa3UyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
        "# pair plot\n",
        "sns.set(style=\"ticks\", color_codes=True)\n",
        "g = sns.pairplot(df[['product_photos_qty','product_name_lenght','product_description_lenght','review_score']],hue='review_score',palette=['#2e4884','grey'])\n",
        "g.savefig(\"pairplot1.png\")"
      ],
      "metadata": {
        "id": "n42xA5s83giU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mm=df[['order_purchase_month_name','price']].groupby('order_purchase_month_name').sum()"
      ],
      "metadata": {
        "id": "35mc4n6A3weV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pi = list(df_mm['price'])\n",
        "li = list(df_mm.index)\n",
        "#dict of months and price value\n",
        "res = {li[i]: pi[i] for i in range(len(li))}"
      ],
      "metadata": {
        "id": "V7YH8ShG38_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "mnths = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug','Sep','Oct','Nov','Dec']\n",
        "weeks=['Sun','Mon','Tue','Wed','Thu','Fri','Sat']\n",
        "res = dict(OrderedDict(sorted(res.items(),key =lambda x:mnths.index(x[0]))))#sorting by month\n",
        "print(res)"
      ],
      "metadata": {
        "id": "OAlakObO3_gR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_3= pd.DataFrame(df.groupby('order_purchase_month_name')['review_score'].agg(lambda x: x.eq(1).sum())).reset_index()\n",
        "\n",
        "# Pandas dataframe grouby count: https://stackoverflow.com/a/19385591/4084039\n",
        "\n",
        "\n",
        "temp_3['total'] = list(pd.DataFrame(df.groupby('order_purchase_month_name')['review_score'].agg([('total','count'),('Avg','mean')]))['total'])\n",
        "temp_3['Avg']   = list(pd.DataFrame(df.groupby('order_purchase_month_name')['review_score'].agg([('total','count'),('Avg','mean')]))['Avg'])\n",
        "temp_3= temp_3.sort_values(by=['total'], ascending=True)"
      ],
      "metadata": {
        "id": "SNyqvHUB4Eqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rem = {list(temp_3.order_purchase_month_name)[i]: list(temp_3.total)[i] for i in range(len(temp_3))}\n",
        "rem = dict(OrderedDict(sorted(rem.items(),key =lambda x:mnths.index(x[0]))))\n",
        "print(rem)"
      ],
      "metadata": {
        "id": "W6NVP5lf4HYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://matplotlib.org/2.2.5/gallery/api/two_scales.html\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'grey'\n",
        "ax1.set_xlabel('Month')\n",
        "ax1.set_ylabel('price', color=color)\n",
        "ax1.plot(list(res.keys()),list(res.values()), color=color)\n",
        "ax1.plot(list(res.keys()),list(res.values()),'C0o', alpha=0.5,color='grey')\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = '#2e4884'\n",
        "ax2.set_ylabel('orders', color=color)  # we already handled the x-label with ax1\n",
        "ax2.plot(list(res.keys()),list(rem.values()), color=color)\n",
        "ax2.plot(list(res.keys()),list(rem.values()),'C0o', alpha=0.5,color='#2e4884')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "#creating  points\n",
        "\n",
        "\n",
        "fig.tight_layout( )  # otherwise the right y-label is slightly clipped\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7nxkL0Ee4UKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* from the above plots we can observe that there is same pattern of total sales and the total order per month between 016 and 2018."
      ],
      "metadata": {
        "id": "_9AqeVPp4fdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2.5. Text Analysis"
      ],
      "metadata": {
        "id": "RPG_qw-x4vcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oder_review.head()\n",
        "oder_review.shape"
      ],
      "metadata": {
        "id": "M8XkaSBS5FYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = oder_review"
      ],
      "metadata": {
        "id": "wa9Cx4rS7My0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_data_title = df1['review_comment_title']\n",
        "review_data = df1.drop(['review_comment_title'], axis=1)\n",
        "\n",
        "# Dropping NaN values\n",
        "review_data = review_data.dropna()\n",
        "review_data_title = review_data_title.dropna()\n",
        "\n"
      ],
      "metadata": {
        "id": "Dw-4wAox6ygl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resetting the reviews index and visualizing the data\n",
        "review_data = review_data.reset_index(drop=True)\n",
        "review_data.head(3)\n",
        "review_data.shape"
      ],
      "metadata": {
        "id": "hbXAKlZP7-G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Resetting the reviews titles index and visualizing the data\n",
        "review_data_title = review_data_title.reset_index(drop=True)\n",
        "review_data_title.head(3)\n",
        "review_data_title.shape"
      ],
      "metadata": {
        "id": "tV5mZRte8O5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n"
      ],
      "metadata": {
        "id": "t5B6sgRy8qdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "id": "fug-a0Qh8r06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n"
      ],
      "metadata": {
        "id": "7gGUmpYo8aFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments = []\n",
        "stop_words = set(stopwords.words('portuguese'))\n",
        "\n",
        "# Drop NaN values from df1\n",
        "df1 = df1.dropna(subset=['review_comment_message'])\n",
        "\n",
        "df1['review_comment_message'] = df1['review_comment_message'].astype(str)\n",
        "\n",
        "for words in df1['review_comment_message']:\n",
        "    if words != 'nan':\n",
        "        only_letters = re.sub(\"[^a-zA-Z]\", \" \", words)\n",
        "        tokens = word_tokenize(only_letters)  # tokenize the sentences\n",
        "        lower_case = [l.lower() for l in tokens]  # convert all letters to lower case\n",
        "        filtered_result = [l for l in lower_case if l not in stop_words]  # Remove stopwords from the comments\n",
        "        comments.append(' '.join(filtered_result))"
      ],
      "metadata": {
        "id": "mOxIvTHaCN1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using wordcloud to visualize the comments\n",
        "unique_string=(\" \").join(comments)\n",
        "wordcloud = WordCloud(width = 2000, height = 1000,background_color='white').generate(unique_string)\n",
        "plt.figure(figsize=(20,12))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.savefig('plot23.png', dpi=400, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2yLeKI4VCYEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#further checking by Counting the words\n",
        "from collections import Counter\n",
        "words = (\" \".join(review_data['review_comment_message'])).lower().split()\n",
        "counts = Counter(words)"
      ],
      "metadata": {
        "id": "SOt_GsMUBryc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Drop NaN values from review_data\n",
        "review_data = review_data.dropna(subset=['review_comment_message'])\n",
        "\n",
        "words = (\" \".join(review_data['review_comment_message'].astype(str))).lower().split()\n",
        "counts = Counter(words)\n",
        "\n",
        "# Remove NaN from counts\n",
        "if np.nan in counts:\n",
        "    del counts[np.nan]\n",
        "\n",
        "print(\"Most frequent words:\")\n",
        "sorted(counts.items(), key=lambda x: x[1], reverse=True)[:15]\n",
        "\n"
      ],
      "metadata": {
        "id": "0_JZ4nrrBwNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Least frequent words:\")\n",
        "sorted(counts.items(), key=lambda x: x[1], reverse=False)[:15]"
      ],
      "metadata": {
        "id": "hKKYMJqgElxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google_trans_new\n"
      ],
      "metadata": {
        "id": "Oi1wYNXEE1sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google_trans_new\n"
      ],
      "metadata": {
        "id": "GJkDHOvRFPTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1\n"
      ],
      "metadata": {
        "id": "3cVmQAM2FVt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "\n",
        "translator = Translator()\n",
        "def translate_text(text, dest, src):\n",
        "    try:\n",
        "        translation = translator.translate(text, dest=dest, src=src)\n",
        "        if translation is not None and hasattr(translation, 'text'):\n",
        "            return translation.text\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Translation Error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "translate_text = translate_text('o,e,produto,a', dest='en', src='pt')\n",
        "if translate_text is not None:\n",
        "    print(translate_text)"
      ],
      "metadata": {
        "id": "xhzSsJo6FrcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the number of words by splitting them by a space\n",
        "words_per_review = df.review_comment_message.apply(lambda x: len(x.split(\" \")))\n",
        "plt.figure(figsize=(10,6))\n",
        "words_per_review.hist(bins = 100)\n",
        "plt.xlabel('Review Length (words)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "agJaggCbFOTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "* The word cloud for the review_messages are shown above.The messages are in Portuguese language and the most frequent words are antes prazo,produto entregue,produto chegou e.t.c.\n",
        "\n",
        "* The most frequent word is ```'o'``` which means ```The``` , other frequent words are ``` e,produto,a``` which means ``` and, product,the``` respectively."
      ],
      "metadata": {
        "id": "BPusnIe0GYkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.6. RFM -Analysis"
      ],
      "metadata": {
        "id": "b7rK1OB9Gho0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is RFM?**\n",
        "\n",
        "Behavioral segmentation by 3 important features:\n",
        "\n",
        "Recency — number of days since the last purchase\n",
        "\n",
        "Frequency — number of transactions made over a given period\n",
        "\n",
        "Monetary — amount spent over a given period of time\n",
        "\n",
        "More details - https://towardsdatascience.com/recency-frequency-monetary-model-with-python-and-how-sephora-uses-it-to-optimize-their-google-d6a0707c5f17"
      ],
      "metadata": {
        "id": "T9_Xj_WA4uoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://towardsdatascience.com/recency-frequency-monetary-model-with-python-and-how-sephora-uses-it-to-optimize-their-google-d6a0707c5f17\n",
        "PRESENT = datetime(2018,9,3)\n",
        "rfm= df.groupby('customer_unique_id').agg({'order_purchase_timestamp': lambda date: (PRESENT - date.max()).days,\n",
        "                                        'order_id': lambda num: len(num),\n",
        "                                        'payment_value': lambda price: price.sum()})\n",
        "rfm.columns=['recency','frequency','monetary']\n",
        "rfm['recency'] = rfm['recency'].astype(int)\n",
        "rfm['frequency'] = rfm['frequency'].astype(int)\n",
        "rfm['monetary'] = rfm['monetary'].astype(float)"
      ],
      "metadata": {
        "id": "yE8ZXpqOGnI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm.head()"
      ],
      "metadata": {
        "id": "N3AHpetKHg8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Plot distribution of R\n",
        "plt.subplot(3, 1, 1)\n",
        "sns.distplot(rfm['recency'], color='black')\n",
        "plt.xlabel('Recency')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Recency')\n",
        "\n",
        "# Add gap between subplots\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "# Plot distribution of F\n",
        "plt.subplot(3, 1, 2)\n",
        "sns.distplot(rfm['frequency'], color='black')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Frequency')\n",
        "\n",
        "# Plot distribution of M\n",
        "plt.subplot(3, 1, 3)\n",
        "sns.distplot(rfm['monetary'], color='black')\n",
        "plt.xlabel('Monetary')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Monetary')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Fd6l00lLHhVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s)\n",
        "* There are three density plots of recency, frequency and monetary are plotted.From the first plot  of recency we can observe that most of the users stayed with olist for long duration which is positive thing but order frequency is less.\n",
        "\n",
        "* from the second plot of frequency most number of transaction or order is less than 5. from the third plot of monetary the maximum amount spend over the given very period is seems to less than 1500 approx."
      ],
      "metadata": {
        "id": "-ZwTiIq3HxqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labels for Recency and Frequency\n",
        "def partition(x):\n",
        "    if x < 10:\n",
        "      return 1\n",
        "    if 10<=x<=35:\n",
        "      return 2\n",
        "    if 35<x<=50:\n",
        "      return 3\n",
        "    if 50<x<=75:\n",
        "      return 4\n",
        "\n",
        "rfm['f_quartile']=rfm['frequency'].map(lambda cw : partition(cw) )\n",
        "\n",
        "# checking the review score now\n",
        "rfm.f_quartile.value_counts()\n",
        "r_labels = range(4, 0, -1);m_labels= range(1,5)\n",
        "\n",
        "rfm['r_quartile'] = pd.qcut(rfm['recency'], 4, r_labels)\n",
        "rfm['m_quartile'] = pd.qcut(rfm['monetary'], 4, m_labels)"
      ],
      "metadata": {
        "id": "3HoDw1M1HtHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm['RFM_Score'] = rfm.r_quartile.astype(str)+ rfm.f_quartile.astype(str) + rfm.m_quartile.astype(str)\n",
        "rfm.head()"
      ],
      "metadata": {
        "id": "9eFF7Gp8L_VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_count_unique = rfm.groupby('RFM_Score')['RFM_Score'].nunique()\n",
        "print(rfm_count_unique.sum())\n",
        "rfm['RFM_Score_s'] = rfm[['r_quartile','f_quartile','m_quartile']].sum(axis=1)\n",
        "print(rfm['RFM_Score_s'].head())"
      ],
      "metadata": {
        "id": "-xfymC_3MEkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define rfm_level function\n",
        "def rfm_level(df):\n",
        "    if df['RFM_Score_s'] >= 9:\n",
        "        return 'Can\\'t Loose Them'\n",
        "    elif ((df['RFM_Score_s'] >= 8) and (df['RFM_Score_s'] < 9)):\n",
        "        return 'Champions'\n",
        "    elif ((df['RFM_Score_s'] >= 7) and (df['RFM_Score_s'] < 8)):\n",
        "        return 'Loyal'\n",
        "    elif ((df['RFM_Score_s'] >= 6) and (df['RFM_Score_s'] < 7)):\n",
        "        return 'Potential'\n",
        "    elif ((df['RFM_Score_s'] >= 5) and (df['RFM_Score_s'] < 6)):\n",
        "        return 'Promising'\n",
        "    elif ((df['RFM_Score_s'] >= 4) and (df['RFM_Score_s'] < 5)):\n",
        "        return 'Needs Attention'\n",
        "    else:\n",
        "        return 'Require Activation'\n",
        "# Create a new variable RFM_Level\n",
        "rfm['RFM_Level'] = rfm.apply(rfm_level, axis=1)\n",
        "# Print the header with top 5 rows to the console\n",
        "rfm.head()"
      ],
      "metadata": {
        "id": "c6Cxz27EMK0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average values for each RFM_Level, and return a size of each segment\n",
        "rfm_level_agg = rfm.groupby('RFM_Level').agg({\n",
        "    'recency': 'mean',\n",
        "    'frequency': 'mean',\n",
        "    'monetary': ['mean', 'count']\n",
        "}).round(1)\n",
        "# Print the aggregated dataset\n",
        "print(rfm_level_agg)\n",
        "rfm_level_agg.columns = rfm_level_agg.columns.droplevel()"
      ],
      "metadata": {
        "id": "w3WaT0ZTMO18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install squarify\n"
      ],
      "metadata": {
        "id": "ZLkoDaENMhcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import squarify\n",
        "\n",
        "rfm_level_agg.columns = ['RecencyMean','FrequencyMean','MonetaryMean', 'Count']\n",
        "#Create our plot and resize it.\n",
        "fig = plt.gcf()\n",
        "ax = fig.add_subplot()\n",
        "fig.set_size_inches(16, 9)\n",
        "squarify.plot(sizes=rfm_level_agg['Count'],\n",
        "              label=['Can\\'t Loose Them',\n",
        "                     'Champions',\n",
        "                     'Loyal',\n",
        "                     'Needs Attention',\n",
        "                     'Potential',\n",
        "                     'Promising',\n",
        "                     'Require Activation'], alpha=.9,color=['#f0f0f0','#d2d2d2','#b4b4b4','#a5a5a5','#969696','#425a90','#2e4884'])\n",
        "plt.title(\"RFM Segments\",fontsize=18)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fa6GKgG8MT5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm.head()"
      ],
      "metadata": {
        "id": "wn-x-4EjMn25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation(s):\n",
        "* Based on the RFM_Score_s all customers are categorised into 7 categories :\n",
        "\n",
        "```\n",
        "'Can\\'t Loose Them' ====  RMF_Score_s  ≥  9\n",
        "'Champions' ==== 8 ≤ RMF_Score_s < 9\n",
        "'Loyal' ==== 7 ≤ RMF_Score_s <8\n",
        "'Needs Attention' ==== 6 ≤ RMF_Score_s <7\n",
        "'Potential' ==== 5 ≤ RMF_Score_s < 6\n",
        "'Promising' ==== 4 ≤ RMF_Score_s < 5\n",
        "'Require Activation' RMF_Score_s <4\n",
        "```\n",
        "\n",
        "* From the above square plot the highest percentage of customers lie within area of category potential.Few areas also there with colored in blue scale which show the percentage of comsumers which requries more attention so that they can retain in olist.\n",
        "\n",
        "* We can use either RMF_Score_s or RMF_Level as feature to solve this problem."
      ],
      "metadata": {
        "id": "QwuTxqo7MyZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#saving file\n",
        "\n",
        "rfm.to_pickle('rfm.pkl')\n",
        "df.to_pickle('final.pkl')"
      ],
      "metadata": {
        "id": "nIYI4jApM0WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions:\n",
        "The target variable/class-label is imbalanced. We should be careful while choosing the performance metric of the models.\n",
        "\n",
        "From the correlation matrix, we found strong positive correlations between the following pairs: (payment_value and price), (product_weight_g and freight_value, as well as product_width_cm), (product_length_cm and product_width_cm), and (product_height_cm and product_weight_g). However, most of the features do not seem to be helpful for the classification task.\n",
        "\n",
        "In the univariate analysis of payment_type, we observed that 96% of users used credit card and boleto, suggesting that this could be an important feature.\n",
        "\n",
        "Additionally, from the univariate analysis of consumer_state, we found that 42% of total consumers are from SP (São Paulo), 12.9% are from RJ (Rio de Janeiro), and 11.7% are from MG (Minas Gerais).\n",
        "\n",
        "Analyzing the product_category feature, we observed that the most ordered products are from the bed_bath_table category, followed by health beauty and sports_leisure between 2016 and 2018. On the other hand, security_and_services products are the least ordered.\n",
        "\n",
        "The different timestamps also seem to be important features, as many new features can be explored from them. We observed that within the period of 2016-2018, the total number of orders received increased until November 2017 and then showed a slight decrement. From the month, day, and time, we observed that the highest number of orders is received in February, on Mondays, and during the afternoon.\n",
        "\n",
        "Numerical features like price, payment_value, freight_value, product_height_cm, and product_length_cm do not seem to be helpful for this classification problem, as observed from the univariate and bivariate analysis.\n",
        "\n",
        "As the review_message can be an important feature for this problem, basic text analysis was performed. The most frequent words found in the reviews are 'o', 'e', 'produto', 'a', etc.\n",
        "\n",
        "RMF Analysis was also conducted to understand whether new features can be created from it. It was found that one numerical or categorical feature can be extracted from it."
      ],
      "metadata": {
        "id": "2fAsBXBDM-uk"
      }
    }
  ]
}